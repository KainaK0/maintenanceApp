{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c627be1547c7c874688ddee1aaaa67b367275f1752d282bff5eb427acd241334"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r'C:\\Users\\jcallomamanib\\Documents\\GitProjects\\maintenanceApp\\02. Data2HR\\data'\n",
    "asset_data = 'AssetData.csv'\n",
    "asset_system = 'AssetStructureA&S.csv'\n",
    "system_component = 'AssetStructureS&C.csv'\n",
    "component_dutie = 'DutieStructureC&D.csv'\n",
    "dutie_data = 'DutieStructureD&D.csv'\n",
    "dutie_resource = 'DutieStructureD&R.csv'\n",
    "wbs = 'WBS.csv'\n",
    "\n",
    "ruteA_D = os.path.join(folder,asset_data)\n",
    "ruteA_S = os.path.join(folder,asset_system)\n",
    "ruteS_C = os.path.join(folder,system_component)\n",
    "ruteC_D = os.path.join(folder,component_dutie)\n",
    "ruteD_D = os.path.join(folder,dutie_data)\n",
    "ruteD_R = os.path.join(folder,dutie_resource)\n",
    "rute_wbs = os.path.join(folder,wbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_D = pd.read_csv(ruteA_D, dtype = {'Cod sap':str})\n",
    "dataA_S = pd.read_csv(ruteA_S, dtype = {'System':str})\n",
    "dataS_C = pd.read_csv(ruteS_C)\n",
    "dataC_D = pd.read_csv(ruteC_D)\n",
    "dataD_D = pd.read_csv(ruteD_D, dtype = {'Specialist':str,'Amount Craft':int,'Time':float})\n",
    "dataD_R = pd.read_csv(ruteD_R, dtype = {'Cod. Material':str})\n",
    "data_wbs = pd.read_csv(rute_wbs)\n",
    "dataD_D.loc[:,'Last date task done']=pd.to_datetime(dataD_D.loc[:,'Last date task done'],format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA OF ASSET INFORMATION\n",
    "# Removing Spanish information\n",
    "asset_SP_EN = ['WBS_1_ES', 'WBS_2_ES', 'WBS_3_ES', 'WBS_4_ES']\n",
    "dataA_D_EN = dataA_D.drop(asset_SP_EN, axis=1)\n",
    "# All Johan&Jorge clearence\n",
    "dataA_D_JJ = dataA_D_EN.loc[dataA_D.loc[:,'Responsable']=='Johan&Jorge',:].sort_values(by='Asset tag').reset_index(drop = True)\n",
    "dataA_D_JJ.to_excel('dataAD.xlsx',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting System data with out other reponsable than Johan and Jorge\n",
    "dataA_S_A = dataA_S\n",
    "dataA_S_JJ = pd.merge(dataA_S_A,dataA_D_EN.loc[:,['Asset tag','Responsable']], how = 'left',left_on='Asset tag',right_on='Asset tag')\n",
    "dataA_S_JJ = dataA_S_JJ.loc[dataA_S_JJ.loc[:,'Responsable'] == 'Johan&Jorge',:].reset_index(drop=True).sort_values(by='key_system')\n",
    "dataA_S_JJ.drop(columns={'Responsable'},inplace = True)\n",
    "dataA_S_JJ.to_excel('dataAS.xlsx',encoding='utf-8-sig',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Components data with out other reponsable than Johan and Jorge\n",
    "dataS_C_A = dataS_C\n",
    "dataS_C_A.loc[:,'key_asset'] = dataS_C.loc[:,'key_system'].str.split(\"|\").str[0]\n",
    "dataS_C_JJ = pd.merge(dataS_C_A,dataA_D_EN.loc[:,['Asset tag','Responsable']], how = 'left',left_on='key_asset',right_on='Asset tag')\n",
    "dataS_C_JJ = dataS_C_JJ.loc[dataS_C_JJ.loc[:,'Responsable'] == 'Johan&Jorge',:].reset_index(drop=True).sort_values(by='key_component')\n",
    "dataS_C_JJ.drop(columns={'key_asset','Asset tag', 'Responsable'},inplace = True)\n",
    "dataS_C_JJ.to_excel('dataSC.xlsx',encoding='utf-8-sig',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Duties data with out other reponsable than Johan and Jorge\n",
    "dataC_D_A = dataC_D\n",
    "dataC_D_A.loc[:,'key_asset'] = dataC_D.loc[:,'key_component'].str.split(\"|\").str[0]\n",
    "dataC_D_JJ = pd.merge(dataC_D_A,dataA_D_EN.loc[:,['Asset tag','Responsable']], how = 'left',left_on='key_asset',right_on='Asset tag')\n",
    "dataC_D_JJ = dataC_D_JJ.loc[dataC_D_JJ.loc[:,'Responsable'] == 'Johan&Jorge',:].reset_index(drop=True).sort_values(by='key_dutie')\n",
    "dataC_D_JJ.drop(columns={'key_asset','Asset tag', 'Responsable'},inplace = True)\n",
    "dataC_D_JJ.to_excel('dataCD.xlsx',encoding='utf-8-sig',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA OF DUTIES AND TASK INFORMATION\n",
    "# Getting Duties data with out other reponsable than Johan and Jorge\n",
    "dataD_D_A = dataD_D\n",
    "dataD_D_A.loc[:,'key_asset'] = dataD_D.loc[:,'key_dutie'].str.split(\"|\").str[0]\n",
    "dataD_D_JJ = pd.merge(dataD_D_A,dataA_D_EN.loc[:,['Asset tag','Responsable']], how = 'left',left_on='key_asset',right_on='Asset tag')\n",
    "dataD_D_JJ = dataD_D_JJ.loc[dataD_D_JJ.loc[:,'Responsable'] == 'Johan&Jorge',:].reset_index(drop=True)\n",
    "dataD_D_JJ.drop(columns={'key_asset','Asset tag', 'Responsable'},inplace = True)\n",
    "\n",
    "# Keeping just Mechanical and Predective specialist\n",
    "dataD_D_MP = dataD_D_JJ.loc[(dataD_D_JJ.loc[:,'Specialist']=='TEC-MEC') | (dataD_D_JJ.loc[:,'Specialist']=='TEC-PRD'),:].reset_index(drop = True)\n",
    "dataD_D_M = dataD_D_JJ.loc[dataD_D_JJ.loc[:,'Specialist']=='TEC-MEC',:].reset_index(drop = True).sort_values(by='key_dutie')\n",
    "dataD_D_P = dataD_D_JJ.loc[dataD_D_JJ.loc[:,'Specialist']=='TEC-PRD',:].reset_index(drop = True).sort_values(by='key_dutie')\n",
    "\n",
    "# Loading Duties data\n",
    "dataD_D_M.to_excel('dataDD_M.xlsx',encoding = 'utf-8-sig',index=False)\n",
    "dataD_D_P.to_excel('dataDD_P.xlsx',encoding = 'utf-8-sig',index=False)\n",
    "\n",
    "# All the non Mechanical or Predective activities are remove\n",
    "dataD_D_M.loc[:,'Man hour'] = dataD_D_M.loc[:,'Time']*dataD_D_M.loc[:,'Amount Craft']\n",
    "dataD_D_P.loc[:,'Man hour'] = dataD_D_P.loc[:,'Time']*dataD_D_P.loc[:,'Amount Craft']\n",
    "\n",
    "# All the conditional activities are remove (1T: first task: all activities with frequency 2T second task: all conditional activities)\n",
    "dataD_D_M_1T = dataD_D_M.loc[dataD_D_M.loc[:,'Maintenance type'] != 'COND',:].reset_index(drop = True)\n",
    "dataD_D_P_1T = dataD_D_P.loc[dataD_D_P.loc[:,'Maintenance type'] != 'COND',:].reset_index(drop = True)\n",
    "dataD_D_MP_2T = dataD_D_MP.loc[dataD_D_MP.loc[:,'Maintenance type'] == 'COND',:].reset_index(drop = True)\n",
    "# Adding Estrategy to the activities\n",
    "dataD_D_M_1T.loc[:,'Strategy'] = dataD_D_M_1T.loc[:,'Frequency'].astype(int).astype(str) + dataD_D_M_1T.loc[:,'Unidad Periodo']\n",
    "dataD_D_P_1T.loc[:,'Strategy'] = dataD_D_P_1T.loc[:,'Frequency'].astype(int).astype(str) + dataD_D_P_1T.loc[:,'Unidad Periodo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Merging all datas csv \n",
    "# Asset&Data(Johan&Jorge) -> Asset&System -> System&Component -> Component&Duties -> \n",
    "# Duties&Data(Mechanical/Predective/Mechanical&Predective)\n",
    "dataA_D_S = pd.merge(dataA_D_JJ,dataA_S,how = 'left',on = 'Asset tag')\n",
    "dataA_S_C = pd.merge(dataA_D_S, dataS_C, how='left', on = 'key_system')\n",
    "dataA_S_C_D = pd.merge(dataA_S_C, dataC_D, how='left', on='key_component')\n",
    "# Merging all with conditional activities\n",
    "dataASCD_M = pd.merge(dataA_S_C_D, dataD_D_M, how = 'inner', on = 'key_dutie')\n",
    "dataASCD_P = pd.merge(dataA_S_C_D, dataD_D_P, how = 'inner', on = 'key_dutie')\n",
    "# Merging all without conditional activities, just first task\n",
    "dataASCD_1TM = pd.merge(dataA_S_C_D, dataD_D_M_1T, how = 'inner', on = 'key_dutie')\n",
    "dataASCD_1TP = pd.merge(dataA_S_C_D, dataD_D_P_1T, how = 'inner', on = 'key_dutie')\n",
    "\n",
    "# Saving the data\n",
    "dataASCD_1TM.to_excel('dataASCD_1TM.xlsx',encoding='utf-8-sig', index=False)\n",
    "dataASCD_1TP.to_excel('dataASCD_1TP.xlsx',encoding='utf-8-sig', index=False)\n",
    "\n",
    "dataASCD_M.to_excel('dataASCD_M.xlsx',encoding='utf-8-sig', index=False)\n",
    "dataASCD_P.to_excel('dataASCD_P.xlsx',encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Adding the pivot column to project\n",
    "dataASCD_M.loc[:,'pivot'] = dataASCD_M.loc[:,'Asset tag'] + '-' + dataAllcompileM.loc[:,'Strategy'] \n",
    "dataASCD_P.loc[:,'pivot'] = dataASCD_P.loc[:,'Asset tag'] + '-' + dataAllcompileM.loc[:,'Strategy'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnfilter = ['key_system', 'Component','Primary task', 'Maintenance type', 'Specialist', 'Constraint', 'Time', 'Amount Craft','Frequency', 'Unidad Periodo','Strategy', 'Date task done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = dataASCD_M.loc[:,['Asset tag','Strategy','Frequency', 'Unidad Periodo','Last date task done','Hour day']].groupby(['Asset tag','Strategy','Frequency', 'Unidad Periodo','Last date task done','Hour day']).size().reset_index()\n",
    "projection.drop(columns = {0},inplace =True)\n",
    "projection.loc[:,'Date plan'] = projection.loc[:,'Last date task done']\n",
    "[row,column] = projection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "planDates = pd.DataFrame(columns = projection.columns)\n",
    "projectionflag = projection\n",
    "\n",
    "for m in range(row):\n",
    "    while projectionflag.loc[m,'Date plan'] < date(2022,1,1):\n",
    "        hour2days = projectionflag.loc[m,'Frequency']/projectionflag.loc[m,'Hour day']\n",
    "        if projectionflag.loc[m,'Unidad Periodo'] == 'H':\n",
    "            delta=timedelta(days = hour2days)\n",
    "        elif  projectionflag.loc[m,'Unidad Periodo'] == 'S':\n",
    "            delta = timedelta(weeks = projectionflag.loc[m,'Frequency'])\n",
    "        elif  projectionflag.loc[m,'Unidad Periodo'] == 'M':\n",
    "            delta = timedelta(weeks = 4*projectionflag.loc[m,'Frequency'])\n",
    "        elif  projectionflag.loc[m,'Unidad Periodo'] == 'A':\n",
    "            delta = timedelta(weeks = 52*projectionflag.loc[m,'Frequency'])\n",
    "        \n",
    "        projectionflag.loc[m,'Date plan'] = projectionflag.loc[m,'Date plan'] + delta\n",
    "        planDates = planDates.append(projectionflag.loc[m,:],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Asset tag, Strategy, Frequency, Unidad Periodo, Last date task done, Hour day, Date plan]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Asset tag</th>\n      <th>Strategy</th>\n      <th>Frequency</th>\n      <th>Unidad Periodo</th>\n      <th>Last date task done</th>\n      <th>Hour day</th>\n      <th>Date plan</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "planDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planDates.loc[:,'pivot'] = planDates.loc[:,'Asset tag'] + '-' + planDates.loc[:,'Strategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAllcompileMplan = pd.merge(dataAllcompileM,planDates.loc[:,['pivot','Date plan']],how='left',on='pivot')\n",
    "# save the datacompileMplan\n",
    "dataAllcompileMplan.to_excel('dataAllcompileMplan.xlsx', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA OF DATES AND PLANIFICATION\n",
    "dataStrategy = dataAllcompileM.loc[:,['Frequency','Unidad Periodo']].groupby(['Frequency','Unidad Periodo']).size().reset_index()\n",
    "dataStrategy.loc[:,0] = dataStrategy.loc[:,'Frequency'].astype(int).astype(str) + dataStrategy.loc[:,'Unidad Periodo']\n",
    "dataStrategy.rename(columns = {0:'claveStrategy'},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "filtertype = dataAllcompileM.loc[:,'Maintenance type'] == 'INSP'\n",
    "filterunidad = dataAllcompileM.loc[:,'Unidad Periodo'] == 'H'\n",
    "filterhour = dataAllcompileM.loc[:,'Frequency'] == 1400\n",
    "dataAllcompileM.loc[filtertype & filterunidad,'Frequency_eq'] = (dataAllcompileM.loc[filtertype & filterunidad,'Frequency']/(24*7)).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAllcompileM.loc[filtertype & filterunidad,['Frequency','Frequency_eq']].groupby(['Frequency','Frequency_eq']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine activities based on similar columns\n",
    "columnfilter = ['key_system', 'Component','Primary task', 'Maintenance type', 'Specialist', 'Constraint', 'Time', 'Amount Craft','Frequency', 'Unidad Periodo']\n",
    "# '2253-PU-212'\n",
    "rowfilter = dataAllcompileM.loc[:,'Asset tag'] == '2221-PU-201'\n",
    "# dataAllcompile.loc[rowfilter,columnfilter]\n",
    "datacombine = dataAllcompileM.loc[rowfilter,columnfilter].groupby(['key_system','Component','Maintenance type','Constraint','Frequency']).agg({'Primary task': lambda x: \"\\n\".join(x)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}